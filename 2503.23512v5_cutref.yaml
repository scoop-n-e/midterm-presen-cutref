# Narrative Understanding Survey - Paper Summary

metadata:
  title: "SCORE: Story Coherence and Retrieval Enhancement for AI Narratives"
  authors:
    - "Qiang Yi"
    - "Yangfan He"
    - "Jianhui Wang"
    - "Xinyuan Song"
    - "Shiyao Qian"
    - "Xinhang Yuan"
    - "Li Sun"
    - "Yi Xin"
    - "Jingqun Tang"
    - "Keqin Li"
    - "Kuan Lu"
    - "Menghao Huo"
    - "Jiaqi Chen"
    - "Tianyu Shi"
  year: 2025
  venue: "arXiv"
  paper_url: "https://jianhuiwemi.github.io/SCORE"

problem_statement:
  background: "Large Language Models (LLMs) can generate creative and engaging narratives from user-specified input, but maintaining coherence and emotional depth throughout these AI-generated stories remains a challenge. LLMs have demonstrated significant capabilities in generating long-form narratives by leveraging large-scale architectures and vast training data. However, maintaining narrative consistency over extended texts, especially in terms of character development and emotional coherence, remains a major challenge."
  
  gap_or_challenge: "LLMs often struggle with inconsistencies when characters or key plot items reappear without proper explanation, disrupting the overall narrative structure. Achieving thematic consistency and managing dynamic plot states is crucial for maintaining logical flow. Inconsistencies in character behavior or emotional tone can negatively impact reader engagement. These challenges indicate a need for more structured approaches in narrative generation."
  
  research_objective: "This work proposes SCORE, a framework for Story Coherence and Retrieval Enhancement, designed to detect and resolve narrative inconsistencies. By tracking key item statuses and generating episode summaries, SCORE uses a Retrieval-Augmented Generation (RAG) approach, incorporating TF-IDF and cosine similarity to identify related episodes and enhance the overall story structure."
  
  significance: "SCORE significantly improves the consistency and stability of narrative coherence compared to baseline GPT models, providing a more robust method for evaluating and refining AI-generated narratives. The framework outperforms baselines in detecting continuity errors and maintaining overall narrative coherence."

tasks:
  - task_name: "Narrative Coherence Evaluation"
    
    task_overview: "Evaluate AI-generated stories for narrative consistency, character coherence, emotional authenticity, and logical tracking of key plot elements across multiple episodes. The framework detects narrative inconsistencies, tracks item states, and ensures continuity throughout episodic storytelling."
    
    input_description: "Episodic stories generated by LLMs, divided into multiple episodes containing dialogues, event descriptions, and narrative elements. Each episode includes raw outputs from language models covering various genres (science fiction, drama, fantasy)."
    
    output_description: "Detailed evaluation reports including consistency scores, coherence ratings, key item status tracking, and identification of continuity errors with corrective recommendations."
  
  - task_name: "Story Question Answering"
    
    task_overview: "Answer complex queries about story content using retrieval-augmented generation. The system retrieves relevant episodes based on semantic similarity and sentiment alignment to provide contextually accurate responses to user questions about plot, characters, or events."
    
    input_description: "User queries about story elements, along with the full story content divided into episodes with summaries and key item tracking information."
    
    output_description: "Detailed answers to user queries with supporting context from relevant episodes, maintaining narrative consistency in responses."

methodology:
  method_name: "SCORE (Story Coherence and Retrieval Enhancement)"
  
  approach_type: "hybrid"
  
  core_technique: "Three-component framework: (1) Continuity Analysis and Key Item Status Correction - Track item states Si(t) ∈ {active, lost, destroyed} across episodes, flag continuity errors when items reappear without explanation. (2) Key Item Interaction Analysis - Generate episode summaries capturing character actions Ac(t), relationships, emotional changes, and interactions Ii(t) with key items. (3) Similarity-Based Episode Evaluation and Sentiment Analysis - Use FAISS vector embeddings and cosine similarity S(ec, ep) to retrieve relevant episodes. Apply sentiment scoring σ(e) ranging 0-1 to ensure emotional consistency. Integrate TF-IDF for keyword extraction and RAG for enhanced context retrieval."
  
  base_models:
    - "GPT-4"
    - "GPT-4o"
    - "GPT-4o-mini"
    - "OpenAI embeddings (for vector space)"
  
  key_innovations:
    - "Automated key item status tracking across episodes"
    - "Episode-level summary generation for plot development tracking"
    - "RAG-based retrieval using both semantic and sentiment similarity"
    - "Systematic continuity error detection and correction"
    - "Integration of TF-IDF and cosine similarity for episode matching"

datasets:
  - dataset_name: "LLM-Generated Story Corpus"
    characteristics: "Diverse set of stories generated by various GPT models covering multiple genres (science fiction, drama, fantasy). Each story divided into episodes containing dialogues, event descriptions, and narrative elements."
    usage: "Evaluation of narrative coherence framework"
    size: null  # Not specified in paper
    domain: "fiction"
    is_new: true
    new_dataset_contribution: "Collection of episodic AI-generated stories for coherence evaluation"

evaluation:
  evaluation_strategy: "Compare SCORE framework against baseline GPT models (GPT-4, GPT-4o, GPT-4o-mini) without enhancement mechanisms. Direct evaluation by uploading full episodes to ChatGPT playground with 'Please evaluate episode n' prompt for baselines. SCORE evaluation uses preprocessed files with key item tracking, RAG-based episode retrieval via FAISS similarity scores, and enriched context for GPT prompts. Metrics focus on narrative coherence, character consistency, plot progression, and emotional authenticity."
  
  main_results: "Consistency: GPT-4o-mini 78.2→82.6 (+4.4), GPT-4o 86.78→88.68 (+1.9), GPT-4 83.21→85.61 (+2.4). Coherence: GPT-4o-mini 76.7→77.5 (+0.8), GPT-4o 82.21→89.91 (+7.7), GPT-4 84.32→86.9 (+2.58). Item Status: All baselines 0→80.5-98 (massive improvement). Complex Questions: GPT-4o-mini 24.56→63.0 (+38.44), GPT-4o 76.32→88.75 (+12), GPT-4 82.34→89.45 (+7.11). 90% overall improvement in analysis accuracy."
  
  metrics_used:
    - "Narrative Coherence (logic and story flow)"
    - "Character Consistency (behavior and development)"
    - "Item Status Tracking (continuity error detection)"
    - "Complex Question Answering (contextual accuracy)"
    - "Sentiment consistency scores"
  
  human_evaluation_summary: null  # No human evaluation reported

results_analysis:
  key_findings:
    - "SCORE achieves 90% improvement in analysis accuracy"
    - "Item status tracking shows 80-98 point improvements from zero baseline"
    - "Complex question answering improves by 7-38 percentage points"
    - "RAG-based retrieval effectively provides relevant context"
    - "Sentiment analysis helps maintain emotional consistency"
    - "Framework successfully detects and corrects continuity errors"
  
  ablation_summary: null  # No ablation study reported

contributions:
  main_contributions:
    - "SCORE: Novel LLM-based evaluation framework for detecting narrative inconsistencies in AI-generated stories."
    - "Integration of RAG approach with episode summaries and key item tracking for improved narrative coherence."
    - "Demonstration of enhanced story consistency through sentiment analysis and similarity-based retrieval."
    - "Significant performance improvements over baseline GPT models in continuity error detection."
  
  limitations:
    - "Dependence on retrieval accuracy - errors in similarity calculation may exclude important context"
    - "Challenges in capturing emotional nuances - sentiment analysis may miss subtle shifts"
    - "Resource intensive - requires considerable computational resources for similarity calculations"
    - "Generalizability concerns - primarily tested on GPT-4-generated stories"

narrative_understanding_aspects:
  - "Narrative Consistency Check"  # Core focus on detecting inconsistencies
  - "Character / Entity Understanding"  # Character behavior and development tracking
  - "Plot / Storyline Extraction"  # Episode summaries and plot tracking
  - "Narrative Assessment"  # Evaluation of story quality and coherence

keywords:
  - "story coherence"
  - "retrieval-augmented generation"
  - "narrative consistency"
  - "episode summarization"
  - "key item tracking"
  - "continuity error detection"
  - "TF-IDF"
  - "cosine similarity"
  - "sentiment analysis"
  - "FAISS"

notes: "Project page: https://jianhuiwemi.github.io/SCORE. Framework achieves 90% improvement in analysis accuracy. Mathematical proof provided for continuity analysis using Markov property and narrative entropy."