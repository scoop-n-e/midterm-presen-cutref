# Narrative Understanding Survey - Paper Summary

metadata:
  title: "Evaluating Character Understanding of Large Language Models via Character Profiling from Fictional Works"
  authors:
    - "Xinfeng Yuan"
    - "Siyu Yuan"
    - "Yuhan Cui"
    - "Tianhe Lin"
    - "Xintao Wang"
    - "Rui Xu"
    - "Jiangjie Chen"
    - "Deqing Yang"
  year: 2024
  venue: "EMNLP"
  paper_url: "https://aclanthology.org/2024.emnlp-main.456/"
  
problem_statement:
  background: "Large language models have demonstrated impressive performance in role-playing agents (RPAs), particularly for fictional characters. The prerequisite for RPAs lies in LLMs' capability to understand characters from fictional works."
  
  gap_or_challenge: "Previous efforts have evaluated character understanding via basic classification tasks like character prediction and personality prediction, or through characteristic imitation focusing on knowledge and linguistic style. These tasks fail to capture the nuanced character understanding of LLMs. Additionally, while character profiles generated by LLMs are widely adopted for RPA development, their effectiveness remains significantly understudied."
  
  research_objective: "This paper systematically evaluates LLMs' capability on the character profiling task, i.e., summarizing profiles for characters from fictional works. The work aims to explore the depth of LLMs' character understanding via generation and evaluate whether the generated profiles can effectively support character comprehension in downstream tasks."
  
  significance: "Character profiling is the first task to explore LLMs' character understanding via generation, which is more challenging than classification tasks. The work contributes to more nuanced comprehension of how LLMs understand characters and has practical implications for RPA development and facilitating human understanding of characters."

tasks:
  - task_name: "Character Profiling"
    
    task_overview: "This task evaluates LLMs' ability to generate comprehensive character profiles from fictional works. Given a character name and the original book content, the model must output a structured profile covering four dimensions: attributes, relationships, events, and personality. The task tests whether LLMs can accurately extract and summarize core character information from long narrative texts."
    
    input_description: "The input consists of a character name and the original content of a fictional work (book). The content is processed using different summarization methods including hierarchical merging, incremental updating, or summarizing in one go for shorter texts."
    
    output_description: "The output is a structured character profile containing four dimensions: attributes (gender, skills, objectives, background), relationships (interpersonal connections), events (chronologically ordered experiences), and personality (lasting characteristics and behaviors). Profiles are limited to 1200 words."
    
  - task_name: "Motivation Recognition"
    
    task_overview: "This downstream task evaluates whether character profiles can support LLMs in understanding character essence by identifying motivations behind decisions. The task involves multiple-choice questions about why characters make specific decisions within story scenarios, testing if profiles enhance character comprehension."
    
    input_description: "The input includes character name, character profile (four dimensions), a character's decision within a scenario, a question about the motivation, and four potential answer choices."
    
    output_description: "The model must select the correct answer from four options that best reflects the character's motivation for the decision. The output is the chosen answer with reasoning."

methodology:
  method_name: "Character Profiling Framework"
  
  approach_type: "neural"
  
  core_technique: "The framework employs three summarization methods for processing book-length texts. Hierarchical Merging segments books into chunks, summarizes them at multiple levels, and merges iteratively until generating a final summary. Incremental Updating starts with the opening segment summary, then refines it by incorporating details from subsequent segments recursively, periodically condensing for relevance. Summarizing in One Go processes entire books under 120K tokens at once using models like GPT-4-Turbo. All methods require structured output across four character dimensions. Evaluation uses Llama-3-70B for factual consistency examination comparing generated profiles with expert references, and GPT-4 for motivation recognition tasks."
  
  base_models:
    - "Mistral-7B-Instruct-v0.2"
    - "Mixtral-8x7B-MoE"
    - "Qwen1.5 series (7B, 14B, 72B)"
    - "Vicuna series (7B, 13B)"
    - "GPT-3.5-Turbo"
    - "GPT-4-Turbo"
    - "Claude-3-Sonnet"
    - "Llama-3-70B (evaluation)"
  
  key_innovations:
    - "First systematic evaluation of LLMs' character profiling capability with structured four-dimensional framework"
    - "Novel motivation recognition task for extrinsic evaluation of profile quality in downstream applications"
    - "Comparison of three summarization methods for processing book-length narratives"
    - "Use of LLM-based evaluation (Llama-3-70B) for factual consistency assessment aligned with human judgment"
    - "Comprehensive error taxonomy identifying five types of profiling errors in complex narratives"

datasets:
  - dataset_name: "CROSS (Character Profiles from SuperSummary)"
    
    characteristics: "High-quality dataset of 126 character profiles from novels published in 2022-2023, sourced from SuperSummary platform with expert-contributed summaries. Profiles are parsed into four dimensions using GPT-4. Includes 47 books with under 120K tokens for one-go summarization testing."
    
    usage: "Primary dataset for character profiling evaluation and motivation recognition tasks"
    
    size: "126 character profiles from novels"
    
    domain: "fiction"
    
    is_new: true
    
    new_dataset_contribution: "First high-quality dataset specifically designed for character profiling evaluation, featuring expert-validated profiles structured across four dimensions. Includes corresponding motivation recognition questions (445 validated from 641 generated) for downstream evaluation."

evaluation:
  evaluation_strategy: "Two-pronged evaluation approach combining intrinsic and extrinsic methods. Intrinsic evaluation uses Factual Consistency Examination with Llama-3-70B comparing generated profiles to expert references on 1-5 scale. Validated with Pearson correlation of 0.752 against human judgment. Extrinsic evaluation employs Motivation Recognition task measuring whether profiles support character understanding through multiple-choice questions. Includes dimension ablation studies to assess importance of each profile dimension."
  
  main_results: "GPT-4-Turbo with incremental updating achieves highest consistency score of 3.60/5 average across dimensions (3.72 attributes, 3.24 relationships, 3.58 events, 3.87 personality). For motivation recognition, best model reaches 57.75% accuracy vs 63.07% with reference profiles and 72.58% human performance. Summarizing-in-one-go method achieves highest scores (3.95/5) on short subset. Event dimension proves most critical for motivation recognition, with 9.21% accuracy drop when excluded. Strong positive correlation observed between consistency scores and MR accuracy."
  
  metrics_used:
    - "Consistency Score (1-5 scale)"
    - "Accuracy (Motivation Recognition)"
    - "Pearson Correlation Coefficient"
    - "Standard Deviation"
  
  human_evaluation_summary: "Human evaluation on 50 randomly selected samples shows Pearson correlation of 0.752 (p=4.3e-12) between human and Llama-3-70B consistency scores. For motivation recognition, two annotators achieved 72.58% average accuracy with 3.32% standard deviation using reference profiles."

results_analysis:
  key_findings:
    - "GPT-4 consistently outperforms other models across all summarization methods"
    - "Larger models (Qwen1.5-72B) generally achieve higher consistency scores"
    - "Models show higher consistency in capturing personality but struggle with event-related information"
    - "Summarizing-in-one-go method maintains narrative coherence best by avoiding information loss from segmentation"
    - "Event dimension has most significant impact on motivation recognition (-9.21% when excluded)"
  
  ablation_summary: "Ablation study reveals event dimension is most critical for motivation recognition. Removing events alone causes 9.21% accuracy drop. Other dimensions show less pronounced impact individually. Reducing profile information increases experimental outcome variance, suggesting model becomes less stable with less detailed profiles."

contributions:
  main_contributions:
    - "First work to systematically evaluate LLMs' character profiling capability, proposing comprehensive evaluation framework with detailed dimensions, tasks, and metrics for assessing character understanding via generation."
    - "Introduction of CROSS dataset containing 126 high-quality character profiles from literature experts, structured across four dimensions with corresponding motivation recognition questions for downstream evaluation."
    - "Extensive experimental validation covering multiple summarization methods and LLMs, demonstrating promising but imperfect character profiling capabilities with clear room for improvement."
    - "Comprehensive error analysis identifying five error types (character/relationship misidentification, key information omission, event/character misinterpretation) revealing challenges with complex narrative structures."
  
  limitations:
    - "Limited to four common character profile dimensions, leaving other potential dimensions unexplored"
    - "Evaluation metrics rely on LLMs potentially introducing bias in consistency assessment"
    - "Possible data leakage despite selecting recent publications"
    - "Room for improvement in summarization method design"

narrative_understanding_aspects:
  - "Character / Entity Understanding"
  - "Narrative Summarisation"
  - "other"  # Character profiling and motivation recognition

keywords:
  - "character profiling"
  - "large language models"
  - "character understanding"
  - "role-playing agents"
  - "motivation recognition"
  - "fictional characters"
  - "long context processing"
  - "narrative summarization"
  - "factual consistency"

notes: "Dataset and code available at https://github.com/Joanna0123/character_profiling. Work reveals that even advanced models generate hallucinations and errors with complex narratives, highlighting need for further improvement in character understanding capabilities."